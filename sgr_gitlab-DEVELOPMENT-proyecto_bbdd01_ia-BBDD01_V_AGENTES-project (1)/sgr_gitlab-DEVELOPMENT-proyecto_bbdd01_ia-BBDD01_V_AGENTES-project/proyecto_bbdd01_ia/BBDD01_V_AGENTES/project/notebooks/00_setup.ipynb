{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24104058-0764-4eaf-9001-72dc2eade836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/jupyter/sgr_gitlab/proyecto_bbdd01_ia/BBDD01_V_AGENTES/project\n",
      "sys.path[0]: /home/jupyter/sgr_gitlab/proyecto_bbdd01_ia/BBDD01_V_AGENTES/project\n",
      "ADC OK | Proyecto: go-cxb-bcx-data9-dtwsgrp01\n",
      "BQ OK  | [Row((1,), {'ok': 0})]\n",
      "SETTINGS:\n",
      "  PROJECT_ID : go-cxb-bcx-data9-dtwsgrp01\n",
      "  REGION     : europe-southwest1\n",
      "  BQ_LOCATION: europe-southwest1\n",
      "  DATASET    : dtwsgr_ds01\n",
      "  TABLA_BASE : `go-cxb-bcx-data9-dtwsgrp01.dtwsgr_ds01.BBDD_01_LIGHT`\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ===== INIT + PATH + SETTINGS UNIFICADOS =====\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "# 1) Localiza la raíz del proyecto (carpeta que contiene /config/settings.py)\n",
    "CANDIDATES = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
    "ROOT = None\n",
    "for c in CANDIDATES:\n",
    "    if (c / \"config\" / \"settings.py\").exists():\n",
    "        ROOT = c\n",
    "        break\n",
    "if ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encuentro 'config/settings.py'. Sitúa el notebook en 'project/notebooks' \"\n",
    "        \"o ajusta este bloque para apuntar a la raíz del proyecto.\"\n",
    "    )\n",
    "\n",
    "# 2) Opcional, trabajar siempre en la raíz del proyecto\n",
    "os.chdir(ROOT)\n",
    "\n",
    "# 3) Asegura que la raíz esté en sys.path y que agents/tools/config sean paquetes\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "for d in [\"agents\", \"tools\", \"config\"]:\n",
    "    pkg = ROOT / d / \"__init__.py\"\n",
    "    pkg.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pkg.touch(exist_ok=True)\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "# ===== IMPORTS BASE DEL NOTEBOOK =====\n",
    "import google.auth\n",
    "from vertexai import init as vertexai_init\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "import altair as alt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "# ===== SETTINGS DEL PROYECTO (fuente única de verdad) =====\n",
    "from config.settings import (\n",
    "    PROJECT_ID, REGION, BQ_LOCATION, DATASET,\n",
    "    TABLA_BASE_FQN   # <- fully-qualified con backticks\n",
    ")\n",
    "\n",
    "# ===== ENV VARS PARA GOOGLE GENAI EN VERTEX =====\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"]      = PROJECT_ID\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"]     = REGION\n",
    "\n",
    "# ===== ADC + BigQuery + Vertex AI =====\n",
    "creds, prj = google.auth.default()\n",
    "print(\"ADC OK | Proyecto:\", prj)\n",
    "vertexai_init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)\n",
    "print(\"BQ OK  |\", list(bq.query(\"SELECT 1 AS ok\").result()))\n",
    "\n",
    "# ===== Altair: API nueva (>=5.5) con fallback =====\n",
    "alt.data_transformers.disable_max_rows()\n",
    "try:\n",
    "    alt.theme.enable(\"opaque\")      # Altair 5.5+\n",
    "except Exception:\n",
    "    alt.themes.enable(\"opaque\")     # Altair <=5.4\n",
    "\n",
    "# ===== Plotly helper (inline, sin Kaleido/CDN) =====\n",
    "def show_plotly_inline(fig, full_html: bool=False, include_js: str=\"inline\"):\n",
    "    \"\"\"\n",
    "    Muestra un gráfico Plotly incrustando JS localmente.\n",
    "    - full_html=False: fragmento HTML (recomendado en notebooks).\n",
    "    - include_js=\"inline\": inyecta plotly.js en el propio output.\n",
    "    \"\"\"\n",
    "    return HTML(fig.to_html(full_html=full_html, include_plotlyjs=include_js))\n",
    "\n",
    "print(\"SETTINGS:\")\n",
    "print(\"  PROJECT_ID :\", PROJECT_ID)\n",
    "print(\"  REGION     :\", REGION)\n",
    "print(\"  BQ_LOCATION:\", BQ_LOCATION)\n",
    "print(\"  DATASET    :\", DATASET)\n",
    "print(\"  TABLA_BASE :\", TABLA_BASE_FQN)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe6798-2617-4e3d-a7a8-719f5dae30ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pendiente:\n",
    "#rehacer los agents (pasarle el codigo de cada agent a gpt, y tiene que modificarlo para crear el archivo prompt)\n",
    "#cada agente, tiene que poder tener una temperatura separada. Cada agente tiene que tener Gemini? \n",
    "#o no hace falta? quizas si? que cada uno sea un gemini independiente con temperatura independiente\n",
    "#implementar lo de que cada agente pugui pensar X temps, el auditor per exemple te que pensar molt, i el composer segurament.\n",
    "# crear el notebook de chat ui"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6b88aee-5225-482b-97c2-0c08d143ecb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "generation_config = GenerateContentConfig(\n",
    "    temperature = 0.7,\n",
    "    top_p = 0.95,\n",
    "    top_k = 40,\n",
    "    max_output_tokens = 100,\n",
    "    thinking_config=ThinkingConfig(\n",
    "        thinking_budget=0     # 0 apaga en; -1 automático\n",
    "    )\n",
    ")\n",
    " \n",
    "prompt = \"Explicame por que el cielo es azul.\"\n",
    " \n",
    "response = client.models.generate_content(\n",
    "    model=model, config=generation_config, contents=prompt\n",
    ")\n",
    "print(response.text)\n",
    " \n",
    "response_schema = {\n",
    "    \"type\": \"array\", #  Especifica que esperarás una lista/array de objetos.\n",
    "    \"items\": {       #  Define la estructura de cada elemento dentro de la lista.\n",
    "        \"type\": \"object\", \n",
    "        \"properties\": { \n",
    "            \"pais\": {\"type\": \"string\"},\n",
    "            \"capital\": {\"type\": \"string\"},\n",
    "            \"poblacion_millones\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"pais\", \"capital\", \"poblacion_millones\"]  # Campos obligatorios en cada objeto\n",
    "    }\n",
    "}\n",
    " \n",
    "# Configurar parámetros del modelo\n",
    "generation_config = GenerateContentConfig(\n",
    "    max_output_tokens=500,\n",
    "    response_mime_type=\"application/json\", #la salida debe ser json\n",
    "    response_schema=response_schema,\n",
    "    thinking_config=ThinkingConfig(\n",
    "            thinking_budget=0     # 0 apaga en; -1 automático\n",
    "        )\n",
    ")\n",
    " \n",
    "prompt = \"Genera una lista de 3 países con sus capitales y población aproximada en millones.\"\n",
    " \n",
    "response = client.models.generate_content(\n",
    "    model=model, config=generation_config, contents=prompt\n",
    ")\n",
    " \n",
    "response_text = response.text\n",
    "result = json.loads(response_text)\n",
    "print(result)\n",
    " \n",
    "Función Compare en Vertex AI Studio\n",
    "La función Compare en Vertex AI Studio no solo permite evaluar modelos distintos, sino también probar variaciones de parámetros de generación en paralelo, como:\n",
    "Temperature → controla la aleatoriedad en las respuestas (más alto = más creativo, más bajo = más determinista).\n",
    "Top-p → ajusta la probabilidad acumulada de palabras candidatas (útil para afinar la diversidad).\n",
    "Max output tokens → define la extensión máxima de la salida.\n",
    "Top-k → limita el número de palabras candidatas consideradas.\n",
    "System instructions → permiten establecer diferentes contextos, estilos o comportamientos del modelo.\n",
    "Con Compare puedes:\n",
    "Configurar diferentes combinaciones de parámetros.\n",
    "Generar salidas simultáneas para la misma entrada.\n",
    "Analizar lado a lado cómo cambian el tono, la precisión o la creatividad.\n",
    "Seleccionar la configuración más adecuada para tu caso de uso (ej. respuestas precisas vs. creativas).\n",
    "En resumen, Compare facilita la exploración y optimización tanto de los hiperparámetros como del comportamiento del modelo, permitiendo entender de manera práctica cómo cada ajuste afecta los resultados generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee1562-0b8a-4a77-bdb7-fb460d68ca81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a65bee8-11dd-46fb-b3e9-d3578c664a07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ agents/artifact_auditor.py listo.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0016a01-48e8-499b-a759-b9e25e2dda96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ tools/viz.py listo.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae9920cc-9ce2-499a-879d-47c00a81257c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ settings.py actualizado con BQT_BYTES_THRESHOLD_MB y BQT_SAFE_AGG_CAP_MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05358d6a-5441-41d0-ae6f-c987c4706681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ loop_runner.py parcheado (web_only sólido + fallback plan).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea704c70-2bc8-4611-97bb-7c2206193787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ tools/web_search.py creado/actualizado.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c76f229-6ea4-4ab4-b66d-0f82977614b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ agents/web_agent.py y agents/composer.py listos.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4f6608c-9873-467a-b2f6-46b35561a7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ agents/loop_runner.py parcheado (import web_agent, sin stage=, text_out con indent correcto)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a7aca45-67bd-4617-b7dd-d847012b44f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral activo: 10240 MB\n",
      "✅ Patch A aplicado. Umbral BYTES_THRESHOLD: 524288000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3983944-2be9-4f7c-b9bd-1503121ef7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prompt creado en: /home/jupyter/sgr_gitlab/proyecto_bbdd01_ia/BBDD01_V_AGENTES/project/prompts/sql_agent_dev.md\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1babe3a0-64e4-421e-a6e9-dbff0d584072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bloque LLM añadido a settings.py\n",
      "Backup: /home/jupyter/sgr_gitlab/proyecto_bbdd01_ia/BBDD01_V_AGENTES/project/config/settings.py.bak_20251107_093035\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8563559-2233-4645-a0d4-270a16c78b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup creado en: /home/jupyter/sgr_gitlab/proyecto_bbdd01_ia/BBDD01_V_AGENTES/project/agents/sql_agent.py.bak_20251107_093830\n",
      "✅ Parche aplicado en: /home/jupyter/sgr_gitlab/proyecto_bbdd01_ia/BBDD01_V_AGENTES/project/agents/sql_agent.py\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kbd01)",
   "language": "python",
   "name": "kbd01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
